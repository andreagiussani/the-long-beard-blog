---
title: "Video Games Sales Data Analysis"
date: 2020-11-08
tags: [Pandas, Matplotlib, Python]
categories: [Intermediate]
header:
  images:
excerpt: "In this post we explore the Video Games sales dataset, and try to perform a data exploration on that source."
---

## Introduction

Have you ever wondered what is the most played video game in the last thirty years? How about which gaming platform is the most used in the last decade? Is Super Mario the most popular game ever? Or is Call of Duty the most appealing one in the last decade?

In this post, we are going to explore advanced data manipulation techniques that are typically used to translate raw data into insightful plots and charts — enabling you to answer these types of questions.

To perform this analysis, we will use the Python language, and we will explore two of the most important data analytics libraries: Pandas and Matplotlib.

Here i will just report the most important insights from the analysis. You can however check the source code to better understand the corresponding code source [here](https://github.com/andreagiussani/miscellaneous/blob/main/the-long-beard-blog/src/2021-02-17-DA01.ipynb).



## 1. Data Manipulation and Cleaning

### 1.1 Data Ingestion

We read the file `'data/vgsales.csv'` using the pandas `read_csv()` function, and store it into the variable `data`.


```python
data = pd.read_csv('data/vgsales.csv')
```

We now check the overall composition of the dataset using the `.info()` method


```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 16598 entries, 0 to 16597
    Data columns (total 11 columns):
     #   Column        Non-Null Count  Dtype  
    ---  ------        --------------  -----  
     0   Rank          16598 non-null  int64  
     1   Name          16598 non-null  object
     2   Platform      16598 non-null  object
     3   Year          16327 non-null  float64
     4   Genre         16598 non-null  object
     5   Publisher     16540 non-null  object
     6   NA_Sales      16598 non-null  float64
     7   EU_Sales      16598 non-null  float64
     8   JP_Sales      16598 non-null  float64
     9   Other_Sales   16598 non-null  float64
     10  Global_Sales  16598 non-null  float64
    dtypes: float64(6), int64(1), object(4)
    memory usage: 1.4+ MB


### 1.2 Data Cleaning

We clearly see there exists a few null values among both the `Publisher` and `Year` columns. The strategy here is to remove them. <br>
Let us remove the null values using the pandas `.dropna()` method:


```python
data.dropna(
  subset=['Publisher', 'Year'],
  how='any',
  inplace=True
)
```

The dataset was generated at the end of the year 2016. Hence, each observation with an occurrence greater than or equal to 2017 must be considered as either corrupted or incorrect, and hence must be removed.


```python
data = data.query('Year < 2017')
```

For more information on the query method, please check this post [here](https://andreagiussani.github.io/the-long-beard-blog/intermediate/PT01/).


### 1.3 Data Consistency

Before moving to a proper data analysis, we need to be sure the data is consistent. By consistency I mean an intrinsic characteristic of the data. For instance, the `Publisher` name might contain a typo, or sometimes a Publisher might be identified by several names.

To investigate this, let us check how `Sony` appears inside our dataset: we hence access to the `Publisher` column, which is of type object, and try to check the different names `Sony` is used for:


```python
data[data['Publisher'].str.contains(
  'sony',
  case=False
  )]['Publisher'].value_counts()
```




    Sony Computer Entertainment            682
    Sony Computer Entertainment Europe      15
    Sony Online Entertainment                8
    Sony Computer Entertainment America      3
    Sony Music Entertainment                 1
    Name: Publisher, dtype: int64



Obviously, the Sony Publisher identifier is not homogeneously identified among observations. We might think of, say, transforming each single possibility to a more general one, say `“Sony”`, to reduce heterogeneity in our data.

To do this, we basically create a custom method, called `merging_info_publisher`, that should be called whenever we wish to perform such kind of cleaning on our data. You can find it in the aforementioned source code. Let us check now how `"Sony"` is mapped inside our dataset after the transformation:


```python
data[data['Publisher'].str.contains(
  'Sony'
)]['Publisher'].value_counts()
```




    Sony    709
    Name: Publisher, dtype: int64

Possibly, this pattern is repeated for different publishers as well. Here we identify a few Publishers that might have different labels inside the dataset, and we apply the `merging_info_publisher` method for each of them.
After the necessary transformation, let us check the absolute distribution of the top 20 Publishers in our dataset:


```python
data['Publisher'].value_counts().head(20)
```




    Electronic Arts                           1341
    Activision                                 996
    Ubisoft                                    931
    Namco                                      928
    Konami                                     823
    THQ                                        712
    Sony                                       709
    Nintendo                                   696
    Sega                                       630
    Take-Two Interactive                       412
    Capcom                                     376
    Atari                                      347
    Tecmo Koei                                 338
    Square Enix                                231
    Warner Bros. Interactive Entertainment     217
    Disney Interactive Studios                 214
    Midway Games                               196
    Eidos Interactive                          196
    505 Games                                  192
    Microsoft Game Studios                     189
    Name: Publisher, dtype: int64


## 2. Total Games Released Each Year

We now want to know when the video game industry experienced a drastic development. Based on the number of games released each year, we might be able to find out when the video games boom happened. We store the distribution of video games releases by year inside the variable `counter_df_by_year`.


```python
counter_df_by_year = filtered_data[
  ['Name', 'Year']
  ].drop_duplicates().groupby('Year').count()

counter_df_by_year.rename(
  columns={'Name': 'Number of Games'},
  inplace=True
)
```

Let us embed that dataframe into a graphical dimension, using matplotlib:


```python
with plt.style.context('ggplot'):
    fig, ax = plt.subplots(figsize=(10,8))
    ax.plot(
      counter_df_by_year.index,
      counter_df_by_year['Number of Games'],
      marker='d'
    )
    ax.set_xlabel('Year')
    ax.set_ylabel('Number of Games')
    ax.set_title('Evolution of Video Games Industry')
    plt.show()
```



<img src="/the-long-beard-blog/assets/images/2021-02-17-DA01/output_35_0.png">


There was a significant boom in the late 2000s. Since then, the distinct number of release has shrunk possibly due to a more convergence to popular titles by both customers and developers.

## 3. Publisher Analysis with respect to Global Sales

Instead of considering absolute frequencies (with respect to the number of video games releases) of the top publishers, a better proxy is to consider the top publishers by Global Sales, identified by the columns `"Global_sales"`.
The result is shown below here:

<img src="/the-long-beard-blog/assets/images/2021-02-17-DA01/output_42_0.png">

Nintendo is the most popular publisher (not surprisingly), followed by two other famous Publishers: Electronic Arts and Activision.


## 4. Understand the most popular Platform by Year

We now want to go further and try to see which Platform was the most popular for each Year. To do so, we again use a proxy the total Global Sales with respect to video games for each specific Platform.

However, this requires a little bit of data wrangling, and therefore we need to perform a few steps to be able to answer to this question. I kindly ask you to look at the source code for more details. I will just briefly explain what i do there:

 1. First of all, we count the number of video games by Platform using the `.groupby()` method;
 2. We then need two steps:
    * pick the top 20 platform with respect to the column `Total Observations`;
    * filter the data with respect to those Platforms.
 3. The resulting dataframe, call it `filtered_data_top20`, is then used to aggregate the data with respect to Global Sales using the pandas `.pivot_table()`. We would like to have, as columns, the platforms' vendor and, as index, the year. Ideally, this is done like this:


```python
pivoted_data = filtered_data_top20.pivot_table(
    index='Year',
    columns='Platform',
    values='Global_Sales',
    aggfunc='sum',
    fill_value=0
)
```

  4. The next part is a little bit tricky: we now want to find the `Platform` which has the top sales for each distinct year. To do that we employ the `NumPy` method `argsort()` which basically allows to sort, for each row, the observations in ascending order. We then select the column names based on the sorting operation, so that in the first place we will find the platform with highest value with respect to the aggregated Global Sales.


The following table shows the tail of the yearly distribution of the most popular platforms during the last 40 years, obtained by following the above steps.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Platform</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>32</th>
      <td>2012.0</td>
      <td>PS3</td>
    </tr>
    <tr>
      <th>33</th>
      <td>2013.0</td>
      <td>PS3</td>
    </tr>
    <tr>
      <th>34</th>
      <td>2014.0</td>
      <td>PS4</td>
    </tr>
    <tr>
      <th>35</th>
      <td>2015.0</td>
      <td>PS4</td>
    </tr>
    <tr>
      <th>36</th>
      <td>2016.0</td>
      <td>PS4</td>
    </tr>
  </tbody>
</table>
</div>


A natural question now is: which was the most popular game in each single year? To answer to this question, we can employ the code below here:

```python
most_popular_games = pd.DataFrame()
for _, row in most_popular_platform_by_year.iterrows():
    year = row['Year']
    platform = row['Platform']

    inner_df = filtered_data.query("Year == @year & Platform==@platform")

    pivoted_table_year_platform = inner_df.pivot_table(
        index = 'Year',
        columns='Name',
        values='Global_Sales',
        aggfunc='sum',
        fill_value=0
    )

    temp_col_max_value = pivoted_table_year_platform.max(axis=1).to_frame() # finds max value by row
    temp_col_max_value.rename(columns={0:'Total sales (ML of units)'}, inplace=True)

    temp_col_max = pivoted_table_year_platform.idxmax(axis=1).to_frame() # find the column with the greatest value on each row
    temp_col_max.rename(columns={0:'Most Wanted Title'}, inplace=True)

    merging_dfs = pd.concat([temp_col_max, temp_col_max_value], axis=1)

    most_popular_games = most_popular_games.append(merging_dfs)
```

The result is as follows:

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Most Wanted Title</th>
      <th>Total sells (ML of units)</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1980.0</th>
      <td>Asteroids</td>
      <td>4.31</td>
    </tr>
    <tr>
      <th>1981.0</th>
      <td>Pitfall!</td>
      <td>4.50</td>
    </tr>
    <tr>
      <th>1982.0</th>
      <td>Pac-Man</td>
      <td>7.81</td>
    </tr>
    <tr>
      <th>1983.0</th>
      <td>Pitfall II: Lost Caverns</td>
      <td>1.31</td>
    </tr>
    <tr>
      <th>1984.0</th>
      <td>Beamrider</td>
      <td>0.27</td>
    </tr>
    <tr>
      <th>1985.0</th>
      <td>Ghostbusters</td>
      <td>0.45</td>
    </tr>
    <tr>
      <th>1986.0</th>
      <td>Solaris</td>
      <td>0.37</td>
    </tr>
    <tr>
      <th>1987.0</th>
      <td>Kung-Fu Master</td>
      <td>0.65</td>
    </tr>
    <tr>
      <th>1988.0</th>
      <td>River Raid II</td>
      <td>0.51</td>
    </tr>
    <tr>
      <th>1989.0</th>
      <td>Double Dragon</td>
      <td>0.47</td>
    </tr>
    <tr>
      <th>1990.0</th>
      <td>Super Mario World</td>
      <td>20.61</td>
    </tr>
    <tr>
      <th>1991.0</th>
      <td>The Legend of Zelda: A Link to the Past</td>
      <td>4.61</td>
    </tr>
    <tr>
      <th>1992.0</th>
      <td>Super Mario Kart</td>
      <td>8.76</td>
    </tr>
    <tr>
      <th>1993.0</th>
      <td>Super Mario All-Stars</td>
      <td>10.55</td>
    </tr>
    <tr>
      <th>1994.0</th>
      <td>Donkey Kong Country</td>
      <td>9.30</td>
    </tr>
    <tr>
      <th>1995.0</th>
      <td>Namco Museum Vol.1</td>
      <td>3.84</td>
    </tr>
    <tr>
      <th>1996.0</th>
      <td>Crash Bandicoot</td>
      <td>6.82</td>
    </tr>
    <tr>
      <th>1997.0</th>
      <td>Gran Turismo</td>
      <td>10.95</td>
    </tr>
    <tr>
      <th>1998.0</th>
      <td>Tekken 3</td>
      <td>7.16</td>
    </tr>
    <tr>
      <th>1999.0</th>
      <td>Gran Turismo 2</td>
      <td>9.49</td>
    </tr>
    <tr>
      <th>2000.0</th>
      <td>Final Fantasy IX</td>
      <td>5.30</td>
    </tr>
    <tr>
      <th>2001.0</th>
      <td>Gran Turismo 3: A-Spec</td>
      <td>14.98</td>
    </tr>
    <tr>
      <th>2002.0</th>
      <td>Grand Theft Auto: Vice City</td>
      <td>16.15</td>
    </tr>
    <tr>
      <th>2003.0</th>
      <td>Need for Speed Underground</td>
      <td>7.20</td>
    </tr>
    <tr>
      <th>2004.0</th>
      <td>Grand Theft Auto: San Andreas</td>
      <td>20.81</td>
    </tr>
    <tr>
      <th>2005.0</th>
      <td>Madden NFL 06</td>
      <td>4.91</td>
    </tr>
    <tr>
      <th>2006.0</th>
      <td>Wii Sports</td>
      <td>82.74</td>
    </tr>
    <tr>
      <th>2007.0</th>
      <td>Wii Fit</td>
      <td>22.72</td>
    </tr>
    <tr>
      <th>2008.0</th>
      <td>Mario Kart Wii</td>
      <td>35.82</td>
    </tr>
    <tr>
      <th>2009.0</th>
      <td>Wii Sports Resort</td>
      <td>33.00</td>
    </tr>
    <tr>
      <th>2010.0</th>
      <td>Kinect Adventures!</td>
      <td>21.82</td>
    </tr>
    <tr>
      <th>2011.0</th>
      <td>Call of Duty: Modern Warfare 3</td>
      <td>13.46</td>
    </tr>
    <tr>
      <th>2012.0</th>
      <td>Call of Duty: Black Ops II</td>
      <td>14.03</td>
    </tr>
    <tr>
      <th>2013.0</th>
      <td>Grand Theft Auto V</td>
      <td>21.40</td>
    </tr>
    <tr>
      <th>2014.0</th>
      <td>Grand Theft Auto V</td>
      <td>11.98</td>
    </tr>
    <tr>
      <th>2015.0</th>
      <td>Call of Duty: Black Ops 3</td>
      <td>14.24</td>
    </tr>
    <tr>
      <th>2016.0</th>
      <td>FIFA 17</td>
      <td>4.77</td>
    </tr>
  </tbody>
</table>
</div>



whereas the following one shows the most sold Title by Platform: this can be easily obtained using simple data manipulation. Interestngly, GTA V was the most sold title for both PS3 and PS4: unbelivable!


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Most Wanted Title</th>
      <th>Total sells (ML of units)</th>
    </tr>
    <tr>
      <th>Platform</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2600</th>
      <td>Solaris</td>
      <td>7.81</td>
    </tr>
    <tr>
      <th>PS</th>
      <td>Tekken 3</td>
      <td>10.95</td>
    </tr>
    <tr>
      <th>PS2</th>
      <td>Need for Speed Underground</td>
      <td>20.81</td>
    </tr>
    <tr>
      <th>PS3</th>
      <td>Grand Theft Auto V</td>
      <td>21.40</td>
    </tr>
    <tr>
      <th>PS4</th>
      <td>Grand Theft Auto V</td>
      <td>14.24</td>
    </tr>
    <tr>
      <th>SNES</th>
      <td>The Legend of Zelda: A Link to the Past</td>
      <td>20.61</td>
    </tr>
    <tr>
      <th>Wii</th>
      <td>Wii Sports Resort</td>
      <td>82.74</td>
    </tr>
    <tr>
      <th>X360</th>
      <td>Kinect Adventures!</td>
      <td>21.82</td>
    </tr>
  </tbody>
</table>
</div>

Surprisingly none of the super marios is mentioned in this list! To conclude, which are the most sold videogames ever?
We are interesting in investigating which were the most sold titles in the last 40 years. To do so, we employ the `.groupby()` method, and store the result into the `most_wanted_vg` variable.


```python
most_wanted_vg = filtered_data_top20[
    ['Name', 'Global_Sales']
].groupby('Global_Sales').sum()
```


```python
most_wanted_vg.sort_values(
  by='Global_Sales',
  ascending=False
).head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
    </tr>
    <tr>
      <th>Global_Sales</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>82.74</th>
      <td>Wii Sports</td>
    </tr>
    <tr>
      <th>35.82</th>
      <td>Mario Kart Wii</td>
    </tr>
    <tr>
      <th>33.00</th>
      <td>Wii Sports Resort</td>
    </tr>
    <tr>
      <th>30.01</th>
      <td>New Super Mario Bros.</td>
    </tr>
    <tr>
      <th>29.02</th>
      <td>Wii Play</td>
    </tr>
    <tr>
      <th>28.62</th>
      <td>New Super Mario Bros. Wii</td>
    </tr>
    <tr>
      <th>24.76</th>
      <td>Nintendogs</td>
    </tr>
    <tr>
      <th>23.42</th>
      <td>Mario Kart DS</td>
    </tr>
    <tr>
      <th>22.72</th>
      <td>Wii Fit</td>
    </tr>
    <tr>
      <th>22.00</th>
      <td>Wii Fit Plus</td>
    </tr>
  </tbody>
</table>
</div>

It looks like the nintendo games are the most sold! The Wii sports was such a huge success for Nintendo. The classic “Mario” games own 4 of Top 10 most popular games.

### Conclusions

I hope you have enjoyed this analysis: it shows how pandas and matplotlib are important to help you in the interpretability of the raw data.

If you want to replicate the results seen in this post, please check the source code [here](https://github.com/andreagiussani/miscellaneous/blob/main/the-long-beard-blog/src/2021-02-17-DA01.ipynb).

If you have enjoyed this post, please do not forget to star the repository where the source code is placed. See you in the next post!
